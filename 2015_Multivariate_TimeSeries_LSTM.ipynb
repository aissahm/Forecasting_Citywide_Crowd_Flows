{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2015_Multivariate_TimeSeries_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So1F2J2iTjVG"
      },
      "source": [
        "## **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzyK46elTmLW"
      },
      "source": [
        "In this jupyter notebook, we build LSTM models for taxi trips from the period 2015 to 2016."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSXHSiaMRHaD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNvtJ-dmTzDc"
      },
      "source": [
        "## **Setting up the environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEzp-qyXUxcI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "e55d4e4a-1fc8-458e-8e7a-7e0e4b2501d0"
      },
      "source": [
        "!pip install holidays\n",
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: holidays in /usr/local/lib/python3.6/dist-packages (0.9.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from holidays) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from holidays) (2.8.1)\n",
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=726c7672a4611d26380959f1a1003f41f15f9f06cf6be1cd13a0d22d702df31a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbfjHUl_TyP1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f1853602-64f7-4cc2-c9be-ac663ef17776"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import datetime\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "import os\n",
        "import holidays\n",
        "\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers \n",
        "import keras.backend as K\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "time: 20.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ou5cdXfUb71"
      },
      "source": [
        "## **Common parameters and functions to all models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux7Ol4WCVDZ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ec9cbae-2e64-464d-d5d8-1ba68548c91a"
      },
      "source": [
        "#initial date for training Jan 1st 2015 Midnight\n",
        "initial_date = datetime.datetime(2015, 1, 1, 0, 0)\n",
        "\n",
        "#validation hour range\n",
        "validation_range = 24*7*2\n",
        "\n",
        "#test hour range\n",
        "test_range = 24*7*3\n",
        "\n",
        "def convertDatetoHourIndex(taxiTripTimeStamp, yeartaxitrip):\n",
        "  taxitripdate = datetime.datetime(year=yeartaxitrip, month=taxiTripTimeStamp[0], day=taxiTripTimeStamp[1], hour=taxiTripTimeStamp[2])\n",
        "  diff = taxitripdate - initial_date\n",
        "  return int(diff.total_seconds() / 3600.0)\n",
        "\n",
        "def returnValidTestIndexes(endTrainingIndex):\n",
        "  startValidationIndex = endTrainingIndex\n",
        "  endValidationIndex = endTrainingIndex + validation_range\n",
        "  startTestIndex = endValidationIndex\n",
        "  return [startValidationIndex, startTestIndex]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 6.17 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmgOOVSkUgSQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d7d92b2-be92-444e-e8fc-f89849f4a953"
      },
      "source": [
        "#CAN BE MODIFIED!!!!!!!\n",
        "end_training_index = convertDatetoHourIndex([9, 7, 8], 2016)\n",
        "test_StartDate = \"2016-09-07 08:00\"\n",
        "test_start_date_title = \"2016_09_07_800\"\n",
        "\n",
        "\n",
        "#loading the dataframe\n",
        "taxitrips_df = pd.read_csv(\"/content/two_years_2015_2016_dataframe.csv\")\n",
        "\n",
        "#list of regions by new/end flows\n",
        "regions_to_loop_newflow = ['26_new', '53_new', '60_new', '62_new', '66_new', '68_new', '72_new', '73_new', '75_new', '76_new', '77_new', '78_new', '82_new', '83_new', '88_new', '125_new']\n",
        "regions_to_loop_endflow = ['26_end', '53_end', '60_end', '62_end', '66_end', '68_end', '72_end', '73_end', '75_end', '76_end', '77_end', '78_end', '82_end', '83_end', '88_end', '125_end']\n",
        "\n",
        "#setting training data\n",
        "forecastHourRange = test_range\n",
        "start_training_index = 0\n",
        "\n",
        "\n",
        "#NO MODIFICATION NEEDED: path to folder containing the forecasts\n",
        "base_results_csv_path_LSTM_twovariate = \"/content/gdrive/My Drive/urban-computing-project/LSTM_twovariate_results/\"\n",
        "base_results_csv_path_LSTM_multivariate = \"/content/gdrive/My Drive/urban-computing-project/LSTM_multivariate_results/\"\n",
        "\n",
        "statistical_method_twovariate = \"LSTM_twovariate\"\n",
        "statistical_method_multivariate = \"LSTM_twovariate\"\n",
        "\n",
        "#federal holidays\n",
        "us_holidays = holidays.UnitedStates()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 122 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8_C1fg8WNLp"
      },
      "source": [
        "**RMSE functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkhz1wQpWMD1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2862add1-cf2b-414f-9a00-86db3a4ba46f"
      },
      "source": [
        "def returnRMSEofTensors(yforecast, y):\n",
        "  yforecast[yforecast < 0] = 0\n",
        "  ydifference = (yforecast - y)**2\n",
        "  rmse = (ydifference.sum()/(y.shape[0]*y.shape[1]))**0.5\n",
        "  return int(rmse)\n",
        "\n",
        "def returnRMSEofTensorsForPeriodForecastArray(yforecast, y, periodForecastArray):\n",
        "  rmseArray = []\n",
        "  for periodForecast in periodForecastArray:\n",
        "    rmse = returnRMSEofTensors(yforecast[:periodForecast], y[:periodForecast])\n",
        "    rmseArray.append(rmse)\n",
        "  return rmseArray\n",
        "\n",
        "def returnAverageValueTaxiFlows(y):\n",
        "  averageflows = y.sum() / (y.shape[0]*y.shape[1])\n",
        "  return int(averageflows)\n",
        "\n",
        "def returnAverageTaxiFlowsArray(y, periodForecastArray):\n",
        "  averageTaxiFlowsArray = []\n",
        "  for periodForecast in periodForecastArray:\n",
        "    averageTaxiFlowsArray.append(returnAverageValueTaxiFlows(y[:periodForecast]))\n",
        "  return averageTaxiFlowsArray\n",
        "\n",
        "def returnRelativeRMSEtoAverage(rmseArray, averageTaxiTripsArray):\n",
        "  relativeRMSEtoAverageArray = []\n",
        "  m = len(rmseArray)\n",
        "  k = 0\n",
        "  while k < m:\n",
        "    if averageTaxiTripsArray[k] > 0:\n",
        "      relativeRMSEtoAverageArray.append(int(100*rmseArray[k]/averageTaxiTripsArray[k]))\n",
        "    else:\n",
        "      relativeRMSEtoAverageArray.append(0)\n",
        "    k = k + 1\n",
        "  return relativeRMSEtoAverageArray\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 24.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezdk45VcWP7D"
      },
      "source": [
        "**File management functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEbUFDGwVIz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad173c77-d338-44c7-c33d-f9c182a59a40"
      },
      "source": [
        "def returnBaseNameOfFileFullPath(resultDatasetPath):\n",
        "    name = resultDatasetPath.split('/')\n",
        "    baseName = name[len(name)-1]\n",
        "    name = baseName.split('.')\n",
        "    return name[0]\n",
        "\n",
        "def returnForecastsInDataframe(yForecastTest, yTest, regionsTitleArray, initialTestingDate):\n",
        "    n = yTest.shape[0]\n",
        "    date_df = pd.date_range(pd.Timestamp(initialTestingDate), periods=n, freq='h')\n",
        "    \n",
        "    region_forecasts_title_array = []\n",
        "    region_test_title_array = []\n",
        "    for regionIDtitle in regionsTitleArray:\n",
        "      region_forecasts_title_array.append(regionIDtitle + \"_forecast\")\n",
        "      region_test_title_array.append(regionIDtitle + \"_test\")\n",
        "    \n",
        "    columns = region_forecasts_title_array + region_test_title_array\n",
        "    y_data = np.concatenate( (yForecastTest, yTest) ,axis=1)\n",
        "    data = np.array(y_data)\n",
        "    df = pd.DataFrame(data=data, columns=columns)\n",
        "\n",
        "    df[\"timestamp\"] = date_df\n",
        "\n",
        "    return df\n",
        "\n",
        "def saveforecastsintoCSV(yForecastTest, yTest, regionsTitleArray, initialTestingDate, resultsCSVFilePath):\n",
        "  df = returnForecastsInDataframe(yForecastTest, yTest, regionsTitleArray, initialTestingDate)\n",
        "  df.to_csv(resultsCSVFilePath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 17.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkXbB_aoa5GJ"
      },
      "source": [
        "**LSTM model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc4ltAaPa3gu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d49ab36-f81d-431e-c351-f816dc5a19eb"
      },
      "source": [
        "def returnLSTMModel(sequenceLength, xtrain, ytrain, batchSize, nweights, initialLearningRate):\n",
        "  generator = TimeseriesGenerator(xtrain, ytrain, length=sequenceLength, batch_size=batchSize)\n",
        "  lstm_model = Sequential()\n",
        "  lstm_model.add(LSTM(nweights, activation='relu', input_shape=(sequenceLength, xtrain.shape[1])))\n",
        "  lstm_model.add(Dense(ytrain.shape[1]))\n",
        "  adamOpti = optimizers.Adam(learning_rate=initialLearningRate)\n",
        "  lstm_model.compile(optimizer=adamOpti, loss='mse')\n",
        "\n",
        "  return [lstm_model, generator]\n",
        "\n",
        "\n",
        "def returnLSTMForecast(lstm_model, sequenceLength, forecastPeriodRange, xtrain, featuresArray):\n",
        "  lstm_predictions_scaled = list()\n",
        "\n",
        "  batch = xtrain[-sequenceLength:]\n",
        "\n",
        "  current_batch = batch.reshape((-1, sequenceLength, xtrain.shape[1]))\n",
        "\n",
        "  j = 0\n",
        "  for i in range(forecastPeriodRange):   \n",
        "      lstm_pred = lstm_model.predict(current_batch)[0]\n",
        "\n",
        "      elem_array = []\n",
        "      for prediction in lstm_pred:\n",
        "        elem_array.append(prediction)\n",
        "\n",
        "      for feature in featuresArray[j]:\n",
        "        elem_array.append(feature)\n",
        "\n",
        "      elem = np.array(elem_array)\n",
        "      elem = elem.reshape((1, xtrain.shape[1]))\n",
        "\n",
        "      lstm_predictions_scaled.append(lstm_pred) \n",
        "\n",
        "      current_batch = np.append(current_batch[0] , elem, axis = 0)\n",
        "      current_batch = current_batch[1:]\n",
        "      current_batch = current_batch.reshape((-1, sequenceLength, xtrain.shape[1]))\n",
        "      j = j + 1\n",
        "\n",
        "  return lstm_predictions_scaled "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 33.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnpenNsHbFkQ"
      },
      "source": [
        "**Simulation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f61AKfSxbJRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d328d3e-f3bd-4246-e325-87efb9bbe392"
      },
      "source": [
        "def runLSTMSimulation(resultsCSVFilePath, regionsTitleArray, dataSets, featuresSets, initialTestingDate, endingIndexForTraining, periodForecastArray,sequenceLength, batchSize, nweights, lstmModelName, numberEpochsArray,learningRateArray, verbose, saveModelToPath = \"No\"):\n",
        "\n",
        "  startValidationIndex, startTestIndex = returnValidTestIndexes(endingIndexForTraining)\n",
        "\n",
        "  #getting the data\n",
        "  y_ = dataSets.copy()\n",
        "  y_train = y_[:startValidationIndex].copy()\n",
        "  y_validation = y_[startValidationIndex:startTestIndex].copy()\n",
        "  y_test = y_[startTestIndex:].copy()\n",
        "  \n",
        "  #features\n",
        "  features_train = featuresSets[:startValidationIndex]\n",
        "  features_validation = featuresSets[startValidationIndex:startTestIndex]\n",
        "  features_test = featuresSets[startTestIndex:]\n",
        "  \n",
        "  #scaling the target data\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  #scaling the data based on data inside the train dataset\n",
        "  scaler.fit(y_train)\n",
        "  scaled_train_data = scaler.transform(y_train)\n",
        "\n",
        "  #the input of the test is the validation set\n",
        "  scaled_test_data = scaler.transform(y_validation)\n",
        "\n",
        "  #combining the data\n",
        "  scaled_train_data_input = np.concatenate((scaled_train_data, features_train), axis=1)\n",
        "\n",
        "  #the input for the test is the data of the validation\n",
        "  scaled_test_data_input = np.concatenate((scaled_test_data, features_validation), axis=1)\n",
        "\n",
        "  #get the lstm model\n",
        "  lstmModel, generator = returnLSTMModel(sequenceLength, scaled_train_data_input, scaled_train_data, batchSize, nweights, learningRateArray[0])\n",
        "\n",
        "  #training: 1st training with first learning rate and number of epochs\n",
        "  lstmModel.fit_generator(generator, epochs=numberEpochsArray[0], verbose=verbose)\n",
        "\n",
        "  #training: 2st training with second learning rate and number of epochs\n",
        "  K.set_value(lstmModel.optimizer.lr, learningRateArray[1])\n",
        "  lstmModel.fit_generator(generator, epochs=numberEpochsArray[1], verbose=verbose)\n",
        "  \n",
        "  #forecasts on validation set\n",
        "  #returnLSTMForecast(lstm_model, sequenceLength, forecastPeriodRange, xtrain, featuresArray)\n",
        "  period_to_forecast = y_validation.shape[0]\n",
        "  lstm_predictions_scaled = returnLSTMForecast(lstmModel, sequenceLength, period_to_forecast, scaled_train_data_input, features_validation)\n",
        "  lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
        "  y_forecast_validation = lstm_predictions.copy()\n",
        "\n",
        "  #forecast on validation period, computing RMSE for validation set\n",
        "  rmse_validation_array = returnRMSEofTensorsForPeriodForecastArray(y_forecast_validation, y_validation, periodForecastArray[0])\n",
        "  average_taxi_trips_validation_array = returnAverageTaxiFlowsArray(y_validation, periodForecastArray[0])\n",
        "  rmse_to_average_taxi_trips_validation_array = returnRelativeRMSEtoAverage(rmse_validation_array, average_taxi_trips_validation_array)\n",
        "  print(\"Validation set results\")\n",
        "  print(\"Region IDs :\", regionsTitleArray)\n",
        "  print(\"Forecasting :\", periodForecastArray[0])\n",
        "  print(\"RMSE :\", rmse_validation_array)\n",
        "  print(\"Average Taxi flows :\", average_taxi_trips_validation_array)\n",
        "  print(\"RMSE to average % :\", rmse_to_average_taxi_trips_validation_array)\n",
        "\n",
        "  #forecast on test period, computing RMSE for test set\n",
        "  period_to_forecast = y_test.shape[0]\n",
        "  lstm_predictions_scaled = returnLSTMForecast(lstmModel, sequenceLength, period_to_forecast, scaled_test_data_input, features_test)\n",
        "  lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
        "  y_forecast_test = lstm_predictions.copy()\n",
        "\n",
        "  rmse_test_array = returnRMSEofTensorsForPeriodForecastArray(y_forecast_test, y_test, periodForecastArray[1])\n",
        "  average_taxi_trips_test_array = returnAverageTaxiFlowsArray(y_test, periodForecastArray[1])\n",
        "  rmse_to_average_taxi_trips_test_array = returnRelativeRMSEtoAverage(rmse_test_array, average_taxi_trips_test_array)\n",
        "  print()\n",
        "  print(\"Test set results\")\n",
        "  print(\"Forecasting :\", periodForecastArray[1])\n",
        "  print(\"RMSE :\", rmse_test_array)\n",
        "  print(\"Average Taxi flows :\", average_taxi_trips_test_array)\n",
        "  print(\"RMSE to average % :\", rmse_to_average_taxi_trips_test_array)\n",
        "\n",
        "  print()\n",
        "  \n",
        "  #save results in CSV\n",
        "  #to save: regionsTitleArray, y_forecast_test, y_test, initialTestingDate, resultsCSVFilePath \n",
        "  saveforecastsintoCSV(y_forecast_test, y_test, regionsTitleArray, initialTestingDate, resultsCSVFilePath)\n",
        "\n",
        "  #save model \n",
        "  if len(saveModelToPath) > 5:\n",
        "    lstmModel.save(saveModelToPath)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 78.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVeSVSwB0YA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "d1f3630b-ddad-4a75-9121-5ba3dea6110c"
      },
      "source": [
        "taxitrips_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>holiday</th>\n",
              "      <th>26_new</th>\n",
              "      <th>26_end</th>\n",
              "      <th>53_new</th>\n",
              "      <th>53_end</th>\n",
              "      <th>60_new</th>\n",
              "      <th>60_end</th>\n",
              "      <th>62_new</th>\n",
              "      <th>62_end</th>\n",
              "      <th>66_new</th>\n",
              "      <th>66_end</th>\n",
              "      <th>68_new</th>\n",
              "      <th>68_end</th>\n",
              "      <th>72_new</th>\n",
              "      <th>72_end</th>\n",
              "      <th>73_new</th>\n",
              "      <th>73_end</th>\n",
              "      <th>75_new</th>\n",
              "      <th>75_end</th>\n",
              "      <th>76_new</th>\n",
              "      <th>76_end</th>\n",
              "      <th>77_new</th>\n",
              "      <th>77_end</th>\n",
              "      <th>78_new</th>\n",
              "      <th>78_end</th>\n",
              "      <th>82_new</th>\n",
              "      <th>82_end</th>\n",
              "      <th>83_new</th>\n",
              "      <th>83_end</th>\n",
              "      <th>88_new</th>\n",
              "      <th>88_end</th>\n",
              "      <th>125_new</th>\n",
              "      <th>125_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2015-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>96</td>\n",
              "      <td>904</td>\n",
              "      <td>818</td>\n",
              "      <td>59</td>\n",
              "      <td>84</td>\n",
              "      <td>1695</td>\n",
              "      <td>1168</td>\n",
              "      <td>123</td>\n",
              "      <td>103</td>\n",
              "      <td>410</td>\n",
              "      <td>382</td>\n",
              "      <td>62</td>\n",
              "      <td>100</td>\n",
              "      <td>94</td>\n",
              "      <td>55</td>\n",
              "      <td>207</td>\n",
              "      <td>231</td>\n",
              "      <td>149</td>\n",
              "      <td>137</td>\n",
              "      <td>169</td>\n",
              "      <td>140</td>\n",
              "      <td>19</td>\n",
              "      <td>23</td>\n",
              "      <td>68</td>\n",
              "      <td>72</td>\n",
              "      <td>39</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>180</td>\n",
              "      <td>1626</td>\n",
              "      <td>1595</td>\n",
              "      <td>118</td>\n",
              "      <td>158</td>\n",
              "      <td>2117</td>\n",
              "      <td>1589</td>\n",
              "      <td>169</td>\n",
              "      <td>156</td>\n",
              "      <td>512</td>\n",
              "      <td>420</td>\n",
              "      <td>56</td>\n",
              "      <td>37</td>\n",
              "      <td>78</td>\n",
              "      <td>36</td>\n",
              "      <td>203</td>\n",
              "      <td>350</td>\n",
              "      <td>171</td>\n",
              "      <td>223</td>\n",
              "      <td>246</td>\n",
              "      <td>255</td>\n",
              "      <td>35</td>\n",
              "      <td>45</td>\n",
              "      <td>50</td>\n",
              "      <td>107</td>\n",
              "      <td>35</td>\n",
              "      <td>68</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>229</td>\n",
              "      <td>253</td>\n",
              "      <td>1967</td>\n",
              "      <td>2107</td>\n",
              "      <td>186</td>\n",
              "      <td>262</td>\n",
              "      <td>2019</td>\n",
              "      <td>1683</td>\n",
              "      <td>212</td>\n",
              "      <td>217</td>\n",
              "      <td>341</td>\n",
              "      <td>388</td>\n",
              "      <td>77</td>\n",
              "      <td>35</td>\n",
              "      <td>91</td>\n",
              "      <td>54</td>\n",
              "      <td>192</td>\n",
              "      <td>326</td>\n",
              "      <td>189</td>\n",
              "      <td>218</td>\n",
              "      <td>274</td>\n",
              "      <td>303</td>\n",
              "      <td>34</td>\n",
              "      <td>54</td>\n",
              "      <td>48</td>\n",
              "      <td>84</td>\n",
              "      <td>42</td>\n",
              "      <td>95</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2015-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>168</td>\n",
              "      <td>245</td>\n",
              "      <td>1529</td>\n",
              "      <td>1791</td>\n",
              "      <td>124</td>\n",
              "      <td>166</td>\n",
              "      <td>1650</td>\n",
              "      <td>1290</td>\n",
              "      <td>163</td>\n",
              "      <td>195</td>\n",
              "      <td>173</td>\n",
              "      <td>289</td>\n",
              "      <td>50</td>\n",
              "      <td>31</td>\n",
              "      <td>79</td>\n",
              "      <td>40</td>\n",
              "      <td>122</td>\n",
              "      <td>235</td>\n",
              "      <td>113</td>\n",
              "      <td>155</td>\n",
              "      <td>163</td>\n",
              "      <td>221</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "      <td>25</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2015-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>39</td>\n",
              "      <td>117</td>\n",
              "      <td>693</td>\n",
              "      <td>823</td>\n",
              "      <td>40</td>\n",
              "      <td>86</td>\n",
              "      <td>1018</td>\n",
              "      <td>663</td>\n",
              "      <td>82</td>\n",
              "      <td>117</td>\n",
              "      <td>61</td>\n",
              "      <td>149</td>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>39</td>\n",
              "      <td>20</td>\n",
              "      <td>37</td>\n",
              "      <td>108</td>\n",
              "      <td>52</td>\n",
              "      <td>102</td>\n",
              "      <td>62</td>\n",
              "      <td>145</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0            timestamp  month  ...  88_end  125_new  125_end\n",
              "0           0  2015-01-01 00:00:00      1  ...      33        2        3\n",
              "1           1  2015-01-01 01:00:00      1  ...      68        9        0\n",
              "2           2  2015-01-01 02:00:00      1  ...      95        1        0\n",
              "3           3  2015-01-01 03:00:00      1  ...      61        0        0\n",
              "4           4  2015-01-01 04:00:00      1  ...      41        0        0\n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "stream",
          "text": [
            "time: 79.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_tSrASgbAmH"
      },
      "source": [
        "### **2variate, LAUNCHING THE SIMULATION PART:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgLqfF3o_WCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "83a7c77d-4482-4112-b97e-f734068c0044"
      },
      "source": [
        "regions_to_loop_endflow = []\n",
        "regions_to_loop_newflow = []\n",
        "\n",
        "for (columnName, columnData) in taxitrips_df.iteritems():\n",
        "  if \"end\" in columnName :\n",
        "    regions_to_loop_endflow.append(columnName)\n",
        "  if \"new\" in columnName:\n",
        "    regions_to_loop_newflow.append(columnName)\n",
        "\n",
        "regions_pairs_to_loop = []\n",
        "\n",
        "p = 0\n",
        "while p < len(regions_to_loop_newflow):\n",
        "  regions_pairs_to_loop.append([regions_to_loop_newflow[p], regions_to_loop_endflow[p]])\n",
        "  p = p + 1\n",
        "\n",
        "print(regions_pairs_to_loop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['26_new', '26_end'], ['53_new', '53_end'], ['60_new', '60_end'], ['62_new', '62_end'], ['66_new', '66_end'], ['68_new', '68_end'], ['72_new', '72_end'], ['73_new', '73_end'], ['75_new', '75_end'], ['76_new', '76_end'], ['77_new', '77_end'], ['78_new', '78_end'], ['82_new', '82_end'], ['83_new', '83_end'], ['88_new', '88_end'], ['125_new', '125_end']]\n",
            "time: 6.68 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDvUcQma2Cxw"
      },
      "source": [
        "### **Testing 2016-09-07 08:00**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLnqAc_6CBm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84ccd90a-81eb-4b9e-da94-63ec2b88fee5"
      },
      "source": [
        "regions_to_loop_flows = [[\"26_new\", \"26_end\"], [\"125_new\", \"125_end\"]]\n",
        "\n",
        "features_array = [\"month\", \"weekday\", \"hour\", \"holiday\"]\n",
        "\n",
        "\n",
        "#MAY BE MODIFIED!!!!!!!\n",
        "statistical_method = \"LSTM_two_variate\"\n",
        "end_validation_index = convertDatetoHourIndex([9, 7, 8], 2016)\n",
        "test_startDate = \"2016-09-07 08:00\"\n",
        "test_start_date_title = \"2016_09_07_800\"\n",
        "base_results_csv_path = \"/content/gdrive/My Drive/urban-computing-project/LSTM_two_variate_results/\"\n",
        "\n",
        "base_results_csv_path = \"/content/\"\n",
        "\n",
        "#setting training data\n",
        "#forecastHourRange = 24*7*3\n",
        "start_training_index = 0\n",
        "end_training_index = end_validation_index - validation_range\n",
        "end_testing_index = end_validation_index + test_range\n",
        "\n",
        "#forecasts parameters\n",
        "period_forecast_array_validation = [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 24*7, 24*7*2]\n",
        "period_forecast_array_test = [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 168, 336, 504]\n",
        "period_forecast_array = [period_forecast_array_validation, period_forecast_array_test]\n",
        "\n",
        "#lstm parameters\n",
        "lstm_model_name = statistical_method\n",
        "sequence_length = 6\n",
        "batch_size = 64\n",
        "n_weights = 420\n",
        "number_epochs_array = [16, 10]\n",
        "learning_rate_array = [0.01, 0.001]\n",
        "verboseValue = 1\n",
        "\n",
        "print(\"Testing on :\", test_startDate)\n",
        "print(\"Features :\", features_array)\n",
        "print()\n",
        "\n",
        "for regionIDsarray in regions_to_loop_flows:\n",
        "\n",
        "  print(\"Region IDs :\", regionIDsarray)\n",
        "\n",
        "  regionsIDstr = \"\"\n",
        "  data_set = array([])\n",
        "  for regionIDval in regionIDsarray:\n",
        "    regionsIDstr = regionsIDstr + \"_\" + regionIDval\n",
        "    y_dataset = array(taxitrips_df[regionIDval][start_training_index:end_testing_index].copy())\n",
        "    y_dataset = y_dataset.reshape(y_dataset.shape[0], 1)\n",
        "\n",
        "    if data_set.shape[0] == 0:\n",
        "      data_set = y_dataset.copy()\n",
        "    else:\n",
        "      data_set = np.concatenate((data_set, y_dataset), axis=1)\n",
        "\n",
        "  features_set = array([])\n",
        "  for feature_title in features_array:\n",
        "    feature_dataset = array(taxitrips_df[feature_title][start_training_index:end_testing_index].copy())\n",
        "    feature_dataset = feature_dataset.reshape(feature_dataset.shape[0], 1)\n",
        "\n",
        "    if features_set.shape[0] == 0:\n",
        "      features_set = feature_dataset.copy()\n",
        "    else:\n",
        "      features_set = np.concatenate((features_set, feature_dataset), axis=1)\n",
        "\n",
        "\n",
        "  results_CSV_FilePath = base_results_csv_path + lstm_model_name + regionsIDstr + \"_\" + test_start_date_title + \".csv\"\n",
        "\n",
        "  print(\"saving to\", results_CSV_FilePath)\n",
        "\n",
        "  runLSTMSimulation(results_CSV_FilePath, regionIDsarray, data_set, features_set, test_startDate, end_training_index, period_forecast_array, sequence_length, batch_size, n_weights, lstm_model_name, number_epochs_array, learning_rate_array, verboseValue)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on : 2016-09-07 08:00\n",
            "Features : ['month', 'weekday', 'hour', 'holiday']\n",
            "\n",
            "Region IDs : ['26_new', '26_end']\n",
            "saving to /content/LSTM_two_variate_26_new_26_end_2016_09_07_800.csv\n",
            "Epoch 1/16\n",
            "226/226 [==============================] - 17s 75ms/step - loss: 12.8607\n",
            "Epoch 2/16\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0076\n",
            "Epoch 3/16\n",
            "226/226 [==============================] - 16s 72ms/step - loss: 0.0060\n",
            "Epoch 4/16\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0046\n",
            "Epoch 5/16\n",
            "226/226 [==============================] - 16s 72ms/step - loss: 0.0037\n",
            "Epoch 6/16\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0031\n",
            "Epoch 7/16\n",
            "226/226 [==============================] - 16s 72ms/step - loss: 0.0029\n",
            "Epoch 8/16\n",
            "226/226 [==============================] - 16s 72ms/step - loss: 0.0032\n",
            "Epoch 9/16\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0028\n",
            "Epoch 10/16\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0028\n",
            "Epoch 11/16\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0025\n",
            "Epoch 12/16\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0027\n",
            "Epoch 13/16\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0030\n",
            "Epoch 14/16\n",
            "226/226 [==============================] - 17s 74ms/step - loss: 0.0025\n",
            "Epoch 15/16\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0032\n",
            "Epoch 16/16\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0026\n",
            "Epoch 1/10\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0022\n",
            "Epoch 2/10\n",
            "226/226 [==============================] - 16s 72ms/step - loss: 0.0021\n",
            "Epoch 3/10\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0022\n",
            "Epoch 4/10\n",
            "226/226 [==============================] - 17s 74ms/step - loss: 0.0021\n",
            "Epoch 5/10\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0021\n",
            "Epoch 6/10\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0021\n",
            "Epoch 7/10\n",
            "226/226 [==============================] - 17s 74ms/step - loss: 0.0021\n",
            "Epoch 8/10\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0021\n",
            "Epoch 9/10\n",
            "226/226 [==============================] - 16s 73ms/step - loss: 0.0021\n",
            "Epoch 10/10\n",
            "226/226 [==============================] - 17s 73ms/step - loss: 0.0021\n",
            "Validation set results\n",
            "Region IDs : ['26_new', '26_end']\n",
            "Forecasting : [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 168, 336]\n",
            "RMSE : [2, 34, 34, 30, 33, 45, 41, 38, 32, 32, 28, 32, 33]\n",
            "Average Taxi flows : [87, 83, 89, 103, 121, 165, 162, 150, 109, 112, 105, 98, 90]\n",
            "RMSE to average % : [2, 40, 38, 29, 27, 27, 25, 25, 29, 28, 26, 32, 36]\n",
            "\n",
            "Test set results\n",
            "Forecasting : [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 168, 336, 504]\n",
            "RMSE : [20, 44, 42, 47, 46, 41, 37, 42, 35, 39, 39, 46, 55, 59]\n",
            "Average Taxi flows : [101, 128, 133, 143, 143, 157, 154, 150, 109, 115, 113, 110, 120, 124]\n",
            "RMSE to average % : [19, 34, 31, 32, 32, 26, 24, 28, 32, 33, 34, 41, 45, 47]\n",
            "\n",
            "time: 7min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPqJoHlYUr5O"
      },
      "source": [
        "26:\n",
        "\n",
        "nweights : 420\n",
        "\n",
        "batch : 64\n",
        "\n",
        "epochs: 15, 10\n",
        "\n",
        "RMSE : [5, 36, 36, 32, 33, 46, 42, 38, 34, 32, 29, 34, 35]\n",
        "\n",
        "Average Taxi : [87, 83, 89, 103, 121, 165, 162, 150, 109, 112, 105, 98, 90]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74WjSKt5vRbD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "670eb465-15a4-4e9d-f8b7-d07fc91f4efe"
      },
      "source": [
        "resultsdf = pd.read_csv(\"/content/LSTM_two_variate__26_new_26_end.csv\")\n",
        "resultsdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>26_new_forecast</th>\n",
              "      <th>26_end_forecast</th>\n",
              "      <th>26_new_test</th>\n",
              "      <th>26_end_test</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>125.312207</td>\n",
              "      <td>89.977704</td>\n",
              "      <td>126.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>2016-09-07 08:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>160.439267</td>\n",
              "      <td>101.281889</td>\n",
              "      <td>216.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>2016-09-07 09:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>175.858911</td>\n",
              "      <td>116.185771</td>\n",
              "      <td>207.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2016-09-07 10:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>187.447994</td>\n",
              "      <td>136.100535</td>\n",
              "      <td>247.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2016-09-07 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>194.948627</td>\n",
              "      <td>159.136458</td>\n",
              "      <td>197.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2016-09-07 12:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  26_new_forecast  ...  26_end_test            timestamp\n",
              "0           0       125.312207  ...         77.0  2016-09-07 08:00:00\n",
              "1           1       160.439267  ...         93.0  2016-09-07 09:00:00\n",
              "2           2       175.858911  ...         84.0  2016-09-07 10:00:00\n",
              "3           3       187.447994  ...        100.0  2016-09-07 11:00:00\n",
              "4           4       194.948627  ...         84.0  2016-09-07 12:00:00\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "stream",
          "text": [
            "time: 30.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW3zUCCpwvPj"
      },
      "source": [
        "### **Testing 5 octobre 8AM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qcGr9aMw1_Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7559c7f-3744-4f2e-d6a6-f195a035dfb6"
      },
      "source": [
        "regions_to_loop_flows = regions_pairs_to_loop #[[\"66_new\", \"66_end\"]]\n",
        "\n",
        "features_array = [\"month\", \"weekday\", \"hour\", \"holiday\"]\n",
        "\n",
        "#MAY BE MODIFIED!!!!!!!\n",
        "statistical_method = \"LSTM_two_var_MWHH\"\n",
        "end_validation_index = convertDatetoHourIndex([10, 5, 8], 2016)\n",
        "test_startDate = \"2016-10-05 08:00\"\n",
        "test_start_date_title = \"2016_10_05_800\"\n",
        "base_results_csv_path = \"/content/gdrive/My Drive/urban-computing-project/LSTM_two_variate_results/\"\n",
        "\n",
        "base_results_csv_path = \"/content/\"\n",
        "\n",
        "#setting training data\n",
        "#forecastHourRange = 24*7*3\n",
        "start_training_index = 0\n",
        "end_training_index = end_validation_index - validation_range\n",
        "end_testing_index = end_validation_index + test_range\n",
        "\n",
        "#forecasts parameters\n",
        "period_forecast_array_validation = [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 24*7, 24*7*2]\n",
        "period_forecast_array_test = [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 168, 336, 504]\n",
        "period_forecast_array = [period_forecast_array_validation, period_forecast_array_test]\n",
        "\n",
        "#lstm parameters\n",
        "lstm_model_name = statistical_method\n",
        "sequence_length = 6\n",
        "batch_size = 64\n",
        "n_weights = 450\n",
        "number_epochs_array = [15, 10]\n",
        "learning_rate_array = [0.01, 0.001]\n",
        "verboseValue = 1\n",
        "\n",
        "print(\"Testing on :\", test_startDate)\n",
        "print(\"Features :\", features_array)\n",
        "print()\n",
        "\n",
        "for regionIDsarray in regions_to_loop_flows:\n",
        "\n",
        "  print(\"Region IDs :\", regionIDsarray)\n",
        "\n",
        "  regionsIDstr = \"\"\n",
        "  data_set = array([])\n",
        "  for regionIDval in regionIDsarray:\n",
        "    regionsIDstr = regionsIDstr + \"_\" + regionIDval\n",
        "    y_dataset = array(taxitrips_df[regionIDval][start_training_index:end_testing_index].copy())\n",
        "    y_dataset = y_dataset.reshape(y_dataset.shape[0], 1)\n",
        "\n",
        "    if data_set.shape[0] == 0:\n",
        "      data_set = y_dataset.copy()\n",
        "    else:\n",
        "      data_set = np.concatenate((data_set, y_dataset), axis=1)\n",
        "\n",
        "  features_set = array([])\n",
        "  for feature_title in features_array:\n",
        "    feature_dataset = array(taxitrips_df[feature_title][start_training_index:end_testing_index].copy())\n",
        "    feature_dataset = feature_dataset.reshape(feature_dataset.shape[0], 1)\n",
        "\n",
        "    if features_set.shape[0] == 0:\n",
        "      features_set = feature_dataset.copy()\n",
        "    else:\n",
        "      features_set = np.concatenate((features_set, feature_dataset), axis=1)\n",
        "\n",
        "\n",
        "  results_CSV_FilePath = base_results_csv_path + lstm_model_name + regionsIDstr + \"_\" + test_start_date_title + \".csv\"\n",
        "\n",
        "  print(\"saving to\", results_CSV_FilePath)\n",
        "\n",
        "  runLSTMSimulation(results_CSV_FilePath, regionIDsarray, data_set, features_set, test_startDate, end_training_index, period_forecast_array, sequence_length, batch_size, n_weights, lstm_model_name, number_epochs_array, learning_rate_array, verboseValue)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on : 2016-10-05 08:00\n",
            "Features : ['month', 'weekday', 'hour', 'holiday']\n",
            "\n",
            "Region IDs : ['66_new', '66_end']\n",
            "saving to /content/LSTM_two_var_MWHH_66_new_66_end_2016_10_05_800.csv\n",
            "Epoch 1/14\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 53.6746\n",
            "Epoch 2/14\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 0.0036\n",
            "Epoch 3/14\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 0.0023\n",
            "Epoch 4/14\n",
            "236/236 [==============================] - 19s 79ms/step - loss: 0.0020\n",
            "Epoch 5/14\n",
            "236/236 [==============================] - 19s 79ms/step - loss: 0.0020\n",
            "Epoch 6/14\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 0.0018\n",
            "Epoch 7/14\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 0.0016\n",
            "Epoch 8/14\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 0.0018\n",
            "Epoch 9/14\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 0.0015\n",
            "Epoch 10/14\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 0.0015\n",
            "Epoch 11/14\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 0.0014\n",
            "Epoch 12/14\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 0.0014\n",
            "Epoch 13/14\n",
            "236/236 [==============================] - 19s 82ms/step - loss: 0.0015\n",
            "Epoch 14/14\n",
            "236/236 [==============================] - 20s 83ms/step - loss: 0.0013\n",
            "Epoch 1/10\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 0.0010\n",
            "Epoch 2/10\n",
            "236/236 [==============================] - 19s 82ms/step - loss: 9.9348e-04\n",
            "Epoch 3/10\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 9.7750e-04\n",
            "Epoch 4/10\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 9.6909e-04\n",
            "Epoch 5/10\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 9.5528e-04\n",
            "Epoch 6/10\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 9.4976e-04\n",
            "Epoch 7/10\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 9.5727e-04\n",
            "Epoch 8/10\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 9.3679e-04\n",
            "Epoch 9/10\n",
            "236/236 [==============================] - 19s 80ms/step - loss: 9.2717e-04\n",
            "Epoch 10/10\n",
            "236/236 [==============================] - 19s 81ms/step - loss: 9.1949e-04\n",
            "Validation set results\n",
            "Region IDs : ['66_new', '66_end']\n",
            "Forecasting : [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 168, 336]\n",
            "RMSE : [167, 170, 163, 142, 130, 145, 136, 130, 114, 146, 164, 140, 158]\n",
            "Average Taxi flows : [1095, 1126, 1071, 1015, 1019, 1051, 1101, 1037, 755, 796, 859, 710, 674]\n",
            "RMSE to average % : [15, 15, 15, 13, 12, 13, 12, 12, 15, 18, 19, 19, 23]\n",
            "\n",
            "Test set results\n",
            "Forecasting : [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 168, 336, 504]\n",
            "RMSE : [109, 85, 83, 72, 70, 77, 104, 98, 108, 172, 183, 168, 174, 180]\n",
            "Average Taxi flows : [868, 890, 878, 861, 878, 927, 1002, 982, 735, 771, 834, 675, 708, 716]\n",
            "RMSE to average % : [12, 9, 9, 8, 7, 8, 10, 9, 14, 22, 21, 24, 24, 25]\n",
            "\n",
            "time: 7min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC4aHeehXQ6M"
      },
      "source": [
        "66:\n",
        "\n",
        "batch 65 \n",
        "nweights 470\n",
        "epochs 10 10\n",
        "\n",
        "RMSE: [161, 183, 178, 154, 145, 135, 127, 132, 109, 115, 129, 110, 144]\n",
        "\n",
        "RMSE (other wiht 465 17 10): [109, 100, 97, 94, 85, 93, 88, 112, 98, 121, 139, 135, 158]\n",
        "\n",
        "Average Taxi flows : [1095, 1126, 1071, 1015, 1019, 1051, 1101, 1037, 755, 796, 859, 710, 674]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMS24l4NVXZt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8b1e925d-18fd-4968-9275-d8ac6f524297"
      },
      "source": [
        "resultsdf = pd.read_csv(\"/content/LSTM_two_variate__66_new_66_end.csv\")\n",
        "resultsdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>66_new_forecast</th>\n",
              "      <th>66_end_forecast</th>\n",
              "      <th>66_new_test</th>\n",
              "      <th>66_end_test</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>998.559728</td>\n",
              "      <td>560.217304</td>\n",
              "      <td>1141.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>2016-10-05 08:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>992.678063</td>\n",
              "      <td>696.645304</td>\n",
              "      <td>1103.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>2016-10-05 09:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>797.702052</td>\n",
              "      <td>676.854485</td>\n",
              "      <td>907.0</td>\n",
              "      <td>803.0</td>\n",
              "      <td>2016-10-05 10:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>763.601174</td>\n",
              "      <td>758.709401</td>\n",
              "      <td>797.0</td>\n",
              "      <td>825.0</td>\n",
              "      <td>2016-10-05 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>842.067610</td>\n",
              "      <td>888.988940</td>\n",
              "      <td>871.0</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>2016-10-05 12:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  66_new_forecast  ...  66_end_test            timestamp\n",
              "0           0       998.559728  ...        595.0  2016-10-05 08:00:00\n",
              "1           1       992.678063  ...        724.0  2016-10-05 09:00:00\n",
              "2           2       797.702052  ...        803.0  2016-10-05 10:00:00\n",
              "3           3       763.601174  ...        825.0  2016-10-05 11:00:00\n",
              "4           4       842.067610  ...       1022.0  2016-10-05 12:00:00\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        },
        {
          "output_type": "stream",
          "text": [
            "time: 25 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPsvWcwUz2nZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fabcccee-74f2-445c-81d7-2b65e89ce439"
      },
      "source": [
        "resultsdf = pd.read_csv(\"/content/LSTM_two_variate_66_new66_end.csv\")\n",
        "resultsdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>66_new_forecast</th>\n",
              "      <th>66_end_forecast</th>\n",
              "      <th>66_new_test</th>\n",
              "      <th>66_end_test</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1010.937213</td>\n",
              "      <td>541.247729</td>\n",
              "      <td>1141.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>2016-10-05 08:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1039.500943</td>\n",
              "      <td>695.708975</td>\n",
              "      <td>1103.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>2016-10-05 09:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>849.303351</td>\n",
              "      <td>689.876416</td>\n",
              "      <td>907.0</td>\n",
              "      <td>803.0</td>\n",
              "      <td>2016-10-05 10:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>784.445345</td>\n",
              "      <td>752.201009</td>\n",
              "      <td>797.0</td>\n",
              "      <td>825.0</td>\n",
              "      <td>2016-10-05 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>885.360155</td>\n",
              "      <td>909.178052</td>\n",
              "      <td>871.0</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>2016-10-05 12:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  66_new_forecast  ...  66_end_test            timestamp\n",
              "0           0      1010.937213  ...        595.0  2016-10-05 08:00:00\n",
              "1           1      1039.500943  ...        724.0  2016-10-05 09:00:00\n",
              "2           2       849.303351  ...        803.0  2016-10-05 10:00:00\n",
              "3           3       784.445345  ...        825.0  2016-10-05 11:00:00\n",
              "4           4       885.360155  ...       1022.0  2016-10-05 12:00:00\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "stream",
          "text": [
            "time: 40.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uManwGqN2i_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "547c6923-f3ec-4ce0-c825-dfc2459ed046"
      },
      "source": [
        "results_df_66_end = pd.read_csv(\"/content/gdrive/My Drive/urban-computing-project/TBATS_results/TBATS_66_end_2016_10_05_800.csv\")\n",
        "results_df_66_new = pd.read_csv(\"/content/gdrive/My Drive/urban-computing-project/TBATS_results/TBATS_66_new_2016_10_05_800.csv\")\n",
        "\n",
        "results_df_66_end.head()\n",
        "\n",
        "all_results_df = pd.DataFrame()\n",
        "\n",
        "all_results_df[\"timestamp\"] = resultsdf[\"timestamp\"].copy()\n",
        "all_results_df[\"y_new_LSTM_forecast\"] = resultsdf[\"66_new_forecast\"].copy()\n",
        "all_results_df[\"y_new\"] = resultsdf[\"66_new_test\"].copy()\n",
        "all_results_df[\"y_new_TBATS_forecast\"] = results_df_66_new[\"yforecast\"].copy()\n",
        "all_results_df[\"y_end_LSTM_forecast\"] = resultsdf[\"66_end_forecast\"].copy()\n",
        "all_results_df[\"y_end\"] = resultsdf[\"66_end_test\"].copy()\n",
        "all_results_df[\"y_end_TBATS_forecast\"] = results_df_66_end[\"yforecast\"].copy()\n",
        "all_results_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>y_new_LSTM_forecast</th>\n",
              "      <th>y_new</th>\n",
              "      <th>y_new_TBATS_forecast</th>\n",
              "      <th>y_end_LSTM_forecast</th>\n",
              "      <th>y_end</th>\n",
              "      <th>y_end_TBATS_forecast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-10-05 08:00:00</td>\n",
              "      <td>1010.937213</td>\n",
              "      <td>1141.0</td>\n",
              "      <td>936.009549</td>\n",
              "      <td>541.247729</td>\n",
              "      <td>595.0</td>\n",
              "      <td>533.711667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-10-05 09:00:00</td>\n",
              "      <td>1039.500943</td>\n",
              "      <td>1103.0</td>\n",
              "      <td>991.403120</td>\n",
              "      <td>695.708975</td>\n",
              "      <td>724.0</td>\n",
              "      <td>685.033680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-10-05 10:00:00</td>\n",
              "      <td>849.303351</td>\n",
              "      <td>907.0</td>\n",
              "      <td>854.976458</td>\n",
              "      <td>689.876416</td>\n",
              "      <td>803.0</td>\n",
              "      <td>714.773246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-10-05 11:00:00</td>\n",
              "      <td>784.445345</td>\n",
              "      <td>797.0</td>\n",
              "      <td>810.130331</td>\n",
              "      <td>752.201009</td>\n",
              "      <td>825.0</td>\n",
              "      <td>778.292041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-10-05 12:00:00</td>\n",
              "      <td>885.360155</td>\n",
              "      <td>871.0</td>\n",
              "      <td>856.986224</td>\n",
              "      <td>909.178052</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>922.485750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             timestamp  y_new_LSTM_forecast  ...   y_end  y_end_TBATS_forecast\n",
              "0  2016-10-05 08:00:00          1010.937213  ...   595.0            533.711667\n",
              "1  2016-10-05 09:00:00          1039.500943  ...   724.0            685.033680\n",
              "2  2016-10-05 10:00:00           849.303351  ...   803.0            714.773246\n",
              "3  2016-10-05 11:00:00           784.445345  ...   825.0            778.292041\n",
              "4  2016-10-05 12:00:00           885.360155  ...  1022.0            922.485750\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "stream",
          "text": [
            "time: 41.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfmSAKiF37Z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1fb324e2-ee82-4e0b-8b12-8547900e633c"
      },
      "source": [
        "results_df_66_end.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>regionID_flow</th>\n",
              "      <th>ytest</th>\n",
              "      <th>yforecast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2016-10-05 08:00:00</td>\n",
              "      <td>66_end</td>\n",
              "      <td>595</td>\n",
              "      <td>533.711667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2016-10-05 09:00:00</td>\n",
              "      <td>66_end</td>\n",
              "      <td>724</td>\n",
              "      <td>685.033680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-10-05 10:00:00</td>\n",
              "      <td>66_end</td>\n",
              "      <td>803</td>\n",
              "      <td>714.773246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2016-10-05 11:00:00</td>\n",
              "      <td>66_end</td>\n",
              "      <td>825</td>\n",
              "      <td>778.292041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2016-10-05 12:00:00</td>\n",
              "      <td>66_end</td>\n",
              "      <td>1022</td>\n",
              "      <td>922.485750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0            timestamp regionID_flow  ytest   yforecast\n",
              "0           0  2016-10-05 08:00:00        66_end    595  533.711667\n",
              "1           1  2016-10-05 09:00:00        66_end    724  685.033680\n",
              "2           2  2016-10-05 10:00:00        66_end    803  714.773246\n",
              "3           3  2016-10-05 11:00:00        66_end    825  778.292041\n",
              "4           4  2016-10-05 12:00:00        66_end   1022  922.485750"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "stream",
          "text": [
            "time: 19.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZr-iAXmJRa6"
      },
      "source": [
        "### **All multivariate series LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPFHUzORJYob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "693381d1-56c4-4ee6-c142-3811124cff2a"
      },
      "source": [
        "all_regions_together_to_loop = []\n",
        "\n",
        "p = 0\n",
        "while p < len(regions_to_loop_newflow):\n",
        "  all_regions_together_to_loop.append(regions_to_loop_newflow[p])\n",
        "  all_regions_together_to_loop.append(regions_to_loop_endflow[p])\n",
        "  p = p + 1\n",
        "\n",
        "print(all_regions_together_to_loop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['26_new', '26_end', '53_new', '53_end', '60_new', '60_end', '62_new', '62_end', '66_new', '66_end', '68_new', '68_end', '72_new', '72_end', '73_new', '73_end', '75_new', '75_end', '76_new', '76_end', '77_new', '77_end', '78_new', '78_end', '82_new', '82_end', '83_new', '83_end', '88_new', '88_end', '125_new', '125_end']\n",
            "time: 2.53 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntIMzRWEJ_pB"
      },
      "source": [
        "regions_to_loop_flows = [all_regions_together_to_loop]\n",
        "\n",
        "features_array = [\"month\", \"weekday\", \"hour\", \"holiday\"]\n",
        "\n",
        "#MAY BE MODIFIED!!!!!!!\n",
        "statistical_method = \"LSTM_multivar_\"\n",
        "end_validation_index = convertDatetoHourIndex([10, 5, 8], 2016)\n",
        "test_startDate = \"2016-10-05 08:00\"\n",
        "test_start_date_title = \"2016_10_05_800\"\n",
        "base_results_csv_path = \"/content/gdrive/My Drive/urban-computing-project/LSTM_multivariate_results/\"\n",
        "\n",
        "base_results_csv_path = \"/content/\"\n",
        "\n",
        "#setting training data\n",
        "#forecastHourRange = 24*7*3\n",
        "start_training_index = 0\n",
        "end_training_index = end_validation_index - validation_range\n",
        "end_testing_index = end_validation_index + test_range\n",
        "\n",
        "#forecasts parameters\n",
        "period_forecast_array_validation = [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 24*7, 24*7*2]\n",
        "period_forecast_array_test = [1, 2, 3, 4, 5, 10, 12, 16, 24, 48, 72, 168, 336, 504]\n",
        "period_forecast_array = [period_forecast_array_validation, period_forecast_array_test]\n",
        "\n",
        "#lstm parameters\n",
        "lstm_model_name = statistical_method\n",
        "sequence_length = 6\n",
        "batch_size = 64\n",
        "n_weights = 2000\n",
        "number_epochs_array = [10, 10]\n",
        "learning_rate_array = [0.01, 0.001]\n",
        "verboseValue = 1\n",
        "\n",
        "print(\"Testing on :\", test_startDate)\n",
        "print(\"Features :\", features_array)\n",
        "print()\n",
        "\n",
        "for regionIDsarray in regions_to_loop_flows:\n",
        "\n",
        "  print(\"Region IDs : ALL REGION IDs\")\n",
        "\n",
        "  regionsIDstr = \"all_regions\"\n",
        "  data_set = array([])\n",
        "  for regionIDval in regionIDsarray:\n",
        "    #regionsIDstr = regionsIDstr + \"_\" + regionIDval\n",
        "    y_dataset = array(taxitrips_df[regionIDval][start_training_index:end_testing_index].copy())\n",
        "    y_dataset = y_dataset.reshape(y_dataset.shape[0], 1)\n",
        "\n",
        "    if data_set.shape[0] == 0:\n",
        "      data_set = y_dataset.copy()\n",
        "    else:\n",
        "      data_set = np.concatenate((data_set, y_dataset), axis=1)\n",
        "\n",
        "  features_set = array([])\n",
        "  for feature_title in features_array:\n",
        "    feature_dataset = array(taxitrips_df[feature_title][start_training_index:end_testing_index].copy())\n",
        "    feature_dataset = feature_dataset.reshape(feature_dataset.shape[0], 1)\n",
        "\n",
        "    if features_set.shape[0] == 0:\n",
        "      features_set = feature_dataset.copy()\n",
        "    else:\n",
        "      features_set = np.concatenate((features_set, feature_dataset), axis=1)\n",
        "\n",
        "\n",
        "  results_CSV_FilePath = base_results_csv_path + lstm_model_name + regionsIDstr + \"_\" + test_start_date_title + \".csv\"\n",
        "\n",
        "  print(\"saving to\", results_CSV_FilePath)\n",
        "  \n",
        "  print()\n",
        "\n",
        "  runLSTMSimulation(results_CSV_FilePath, regionIDsarray, data_set, features_set, test_startDate, end_training_index, period_forecast_array, sequence_length, batch_size, n_weights, lstm_model_name, number_epochs_array, learning_rate_array, verboseValue)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}